= DCA0445 - Processamento Digital de Imagens
Denis Medeiros <denis@dimap.ufrn.br> Pedro Henrique <pedrohenriquedemedeiros@gmail.com>
:toc:
:toc-placement: left
:toc-title: Sumário
:caution-caption: Cuidado 
:important-caption: Importante 
:note-caption: Nota 
:tip-caption: Dica 
:warning-caption: Atenção 
:appendix-caption: Apêndices 
:example-caption: Exemplo 
:figure-caption: Figura 
:table-caption: Tabela
:stem:
//:numbered:
:source-highlighter: pygments
:icons: font
:linkattrs:
:imagesdir: ./img
:iconsdir: ./icons
:stylesdir: ./css
:scriptsdir: ./js
:sourcedir: ./src

Esta página contém uma série de exercícios sobre processamento digital de imagens implementados em C++ com a biblioteca OpenCV. Todos eles, bem como os textos introdutórios são de crédito do professor Dr. link:http://agostinhobritojr.github.io/[Agostinho de Medeiros Brito Junior, window="_blank"], professor da Universidade Federal do Rio Grande do Norte e responsável pelo curso link:http://agostinhobritojr.github.io/tutoriais/pdi/[DCA0445 - Processamento Digital de Imagens, window="_blank"].

== Manipulando pixels em uma imagem

=== Seção 3.2 - Exercício 1
****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/pixels.cpp[exemplos/pixels.cpp, window="_blank"] como referência, implemente um  programa regions.cpp. Esse programa deverá solicitar ao usuário as coordenadas  de dois pontos stem:[P_1] e stem:[P_2]  localizados dentro dos limites do  tamanho da imagem e exibir que lhe for fornecida. Entretanto, a região definida  pelo retângulo de vértices opostos definidos pelos pontos stem:[P_1] e stem:[P_2] será exibida com o negativo da imagem na região correspondente. 

O efeito é ilustrado na figura regiões (abaixo).

[[img-regioes]] 
.Figura regioes.png
image::regioes.png[Regiões, 400, 400] 
****

Para resolver o exercício acima, o seguinte programa foi desenvolvido:

.regioes.cpp
[[regioes]]
[source,cpp,linenums]
----
include::{sourcedir}/regioes/regioes.cpp[]
----

A estratégia adotada neste programa consiste em receber do usuário dois pontos, criar um retângulo a partir deles e calcular o negativo deste retângulo. 

As primeiras linhas do programa (linha 21 à linha 36) consiste na validação dos dados fornecidos pelo usuário, ou seja, se o usuário inseriu o número correto as coordenadas x e y de dois pontos e depois se também inseriu uma imagem para retirar o negativo de uma região dela. Depois nas linhas 39 à 64 temos a verificação de que os dados referentes aos dois pontos necessários ao programa são de fato números, pelo uso da função stoi() e então verifica-se se os pontos pertencem a imagem utilizando os comandos imagem.rols e imagem.cols. 

Uma vez que os dois pontos são válidos, é criado um retângulo (linha 66) e, finalmente, é relizado uma iteração sob todos aqueles pixels representados pelo retângulo dentro da própria matriz __image__ (linha 67 à linha 73), de modo que é calculado o negativo de cada pixel subtraindo seu  valor de 255, em que os pixels são acessados pelo método at, recebendo o dado __unsigned char__ da imagem em tons de cinza. Por fim, a imagem processada é exibida na tela.


====
.Exemplo de execução
* Comando: ./regioes onca.png 20 20 200 200
* Foto de entrada: 

[[img-onca]] 
.Figura onca.png original
image::onca.png[Regiões, 400, 400] 

* Foto de saída: 

[[img-onca-regions]] 
.Figura onca.png após processamento
image::onca-regioes.png[Regiões, 400, 400] 

====

=== Seção 3.2 - Exercício 2
****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/pixels.cpp[exemplos/pixels.cpp, window="_blank"] como referência, implemente um programa trocaregioes.cpp. Seu programa deverá trocar os quadrantes em diagonal na imagem. Explore o uso da classe Mat e seus construtores para criar as regiões que serão trocadas. O efeito é ilustrado na Figura Troca de regiões (abaixo).

[[img-regioes]] 
.Figura trocaregioes.png
image::trocaregioes.png[Troca Regiões, 400, 400] 
****

A versão modificada do programa pixels.cpp pode ser vista abaixo:

.trocaregioes.cpp
[[trocaregioes]]
[source,cpp,linenums]
----
include::{sourcedir}/trocaregioes/trocaregioes.cpp[]
----

O objetivo do programa acima foi criar 4 sub-matrizes representando cada quadrante para que depois elas pudessem ser concantenadas em uma nova matriz, de modo a representar os quadrantes trocados.

A criação das submatrizes ocorrem utilizando o próprio construtor da classe *Mat* (da linha 39 à 42), que permite receber a matriz original e um retângulo representando a ser extraída para criação da nova submatriz. Os retângulos são montados tomando como referência o início, fim e pontos médios horizontais e verticais da matriz original.

Com as submatrizes criadas, primeiro são montadas as partes superior e inferior do resultado final (linhas 48 e 53), através da função hconcat(), que primeiro realiza o concatenamento horizontal da metade de baixo da figura original e depois o concatenamento da metade de cima da figura original, em que as submatrizes q1, q2, q3 e q4 são colocadas nas matrizes temp1 e temp2. Com esses dois resultados intermediários, por fim, é realizado um concatenamento vertical (linha 58), com a função vconcat(), que produz o resultado final.

====
.Exemplo de execução
* Comando: ./trocaregioes gato.png
* Foto de entrada: 

[[img-gato]] 
.Figura gato.png original
image::gato.png[Troca Regioes, 400, 400] 

* Foto de saída: 

[[img-gato-trocaregioes]] 
.Figura gato.png após processamento
image::gato-trocaregioes.png[Regiões, 400, 400] 

====

== Preenchendo regiões

=== Seção 4.2 - Exercício 1
****
Observando-se o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/labeling.cpp[labeling.cpp] como exemplo, é possível verificar que caso existam mais de 255 objetos na cena, o processo de rotulação poderá ficar comprometido. Identifique a situação em que isso ocorre e proponha uma solução para este problema.
****

O algoritmo padrão de labeling fornecido pelo professor contem um problema, pois utiliza a própria cor do pixel rotulado para armazenar a contagem de elementos. No caso de uma imagem em escala de cinza, em que cada pixel é representado por 1 byte, logo poder-se-ia contar apenas 255 elementos. Uma abordagem diferente seria utilizar a cor do pixel como um tipo de classificação para os objetos contados, de modo que os pixels de uma mesma categoria assumam apenas um rótulo específico, sendo reservado um contador à parte para contar quantos elementos dessa categoria foram encontrados.

=== Seção 4.2 - Exercício 2

****
Aprimore o algoritmo de contagem apresentado para identificar regiões com ou sem buracos internos que existam na cena. Assuma que objetos com mais de um buraco podem existir. Inclua suporte no seu algoritmo para não contar bolhas que tocam as bordas da imagem. Não se pode presumir, a priori, que elas tenham buracos ou não.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/labeling.cpp[labeling.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo: 

.rotulacao.cpp
[[rotulacao]]
[source,cpp,linenums]
----
include::{sourcedir}/rotulacao/rotulacao.cpp[]
----

A ideia por trás da contagem das bolhas baseiou-se no princípio de rotulação. Os rótulos foram definidos no início do programa, pois já sabia-se, a princípio, quais eram as cores de fundo e dos objetos da cena (linha 4 à linha 7).

Para realizar isso, foi necessário, inicialmente, remover todos os objetos presentes nas bordas da imagem, já que não é possível saber se eles continham ou não buracos iternos na região exterior à imagem (da linha 38 à linha 61). Para isso, foi utilizado um algoritmo de _flood fill_, mudando a cor do objeto encontrado para a mesma cor de fundo da cena.

Uma vez que as imagens localizadas na borda foram removidas, o passo seguinte foi mudar a cor de fundo da cena através do mesmo algoritmo de _flood fill_, iniciando do primeiro pixel da matriz da imagem (linha 64 à linha 66). Isso foi feito com o objetivo de fazer com que os elementos que continham buracos continuassem com tais buracos na cor de fundo antiga, já que, caso um objeto desses não fosse completamente fechado, o buraco seria preenchido pela nova cor de fundo.

Por fim, foi feita uma busca na imagem por qualquer região que ainda estivesse rotulado com a cor de fundo inicial (linha 69 à 81). Tal região seria, consequentemente, um buraco dentro de um objeto. Assim, o número de bolhas seria exatamente igual ao número de buracos encontrados. 


====
.Exemplo de execução
* Comando: ./rotulacao bolhas.png
* Foto de entrada: 

[[img-bolhas]] 
.Figura bolhas.png original
image::bolhas.png[Troca Regioes, 400, 400] 

* Foto de saída: 

[[img-gato-trocaregioes]] 
.Figura bolhas.png após processamento
image::bolhas-rotulacao.png[Regiões, 400, 400] 

====

== Manipulação de histogramas

=== Seção 5.2 - Exercício 1

****
Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa equalize.cpp. Este deverá, para cada imagem capturada, realizar a equalização do histogram antes de exibir a imagem. Teste sua implementação apontando a câmera para ambientes com iluminações variadas e observando o efeito gerado. Assuma que as imagens processadas serão em tons de cinza.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/histogram.cpp[histogram.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo:

.equalizador.cpp
[[equalizador]]
[source,cpp,linenums]
----
include::{sourcedir}/equalizador/equalizador.cpp[]
----

A ideia por trás desse programa consiste em fazer a captura de uma imagem a partir da camera do programador e então fazer o processo de equalização da imagem, o qual consiste em uma distribuição mais uniforme dos valores da intensidade da distribuição, nesse caso o histograma.

Inicialmente o programa realiza a captura de um frame a partir da camera do computador do programador através da classe do opencv VideoCapture, evidenciado na linha 9. Nas linhas 32 e 33 define-se a largura e altura das imagens que serão usadas para desenhar os histogramas.  As imagens são criadas com o tipo CV_8UC1, ou seja, com 8 bits por pixel, com tipo de dados unsigned char contendo 1 canal de cor.

O processo de conversão da imagem colorida para a escala de cinza, através da função cvtColor(), evidenciado na linha 47. Depois temos o uso da função equalizeHist() para a equalização do histograma, evidenciado na linha 49. As outras linhas de código fazem o cálculo do histograma com a função calcHist(), sua normalização com a função normalize(), em relação ao número de linhas da imagem equalizada, a inserção dos histogramas nos frames através da funções line() e copyTo() e por fim uma mensagem para distinção das imagens mostradas nos frames com a função putText. 

====
.Exemplo de execução
* Comando: ./equalizador 
* Fotos de saída: 

[[img-ImagemOriginalEscalaCinza]] 
.Figura ImagemOriginalEscalaCinza.png 
image::ImagemOriginalEscalaCinza.png[ImagemOriginalEscalaCinza, 400, 400] 

[[img-ImagemEqualizada]] 
.Figura ImagemEqualizada.png 
image::ImagemEqualizada.png[ImagemEqualizada, 400, 400] 

====



== Filtragem Espacial I

=== Seção 6.2 Exercício 1

****
Utilizando o programa exemplos/filtroespacial.cpp como referência, implemente um programa laplgauss.cpp. O programa deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Compare o resultado desse filtro com a simples aplicação do filtro laplaciano.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/filtroespacial.cpp[filtroespacial.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo:

.laplgauss.cpp
[[laplgauss]]
[source,cpp,linenums]
----
include::{sourcedir}/laplgauss/laplgauss.cpp[]
----

A ideia básica do programa é verificar a utilização dos diversos filtros espaciais definidos pelo professor no  link para o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/filtroespacial.cpp[filtroespacial.cpp] e que foram modificados no programa laplgauss.cpp e então aplicamos um filtro do laplaciano do gaussiano.

====
.Exemplo de execução
* Comando: ./laplgauss 
* Fotos de saída: 

[[img-Imagem_Filtro_Vertical]] 
.Figura Imagem_Filtro_Vertical.png 
image::Imagem_Filtro_Vertical.png[Imagem_Filtro_Vertical, 400, 400] 

[[img-Imagem_Filtro_Horizontal]] 
.Figura Imagem_Filtro_Horizontal.png 
image::Imagem_Filtro_Horizontal.png[Imagem_Filtro_Horizontal, 400, 400] 

[[img-Imagem_Filtro_Mediana]] 
.Figura Imagem_Filtro_Mediana.png 
image::Imagem_Filtro_Mediana.png[Imagem_Filtro_Mediana, 400, 400] 

[[img-Imagem_Filtro_Gauss]] 
.Figura Imagem_Filtro_Gauss.png 
image::Imagem_Filtro_Gauss.png[Imagem_Filtro_Gauss, 400, 400] 

[[img-Imagem_Filtro_Laplaciano]] 
.Figura Imagem_Filtro_Laplaciano.png 
image::Imagem_Filtro_Laplaciano.png[Imagem_Filtro_Laplaciano, 400, 400]

[[img-Imagem_Filtro_LaplacianoGaussiano]] 
.Figura Imagem_Filtro_LaplacianoGaussiano.png 
image::Imagem_Filtro_LaplacianoGaussiano.png[Imagem_Filtro_LaplacianoGaussiano, 400, 400]
====

As linhas 7 a 44 mostram os diferentes tipos de máscaras utilizadas, as quais são:

* Media
* Gauss
* Horizontal
* Vertical
* Laplaciano
* Laplaciano do gaussiano

A máscara do laplaciano do gaussiano foi obtida através da operação de convolução entre as máscaras de gauss e laplaciana.

As linhas 59 a 69 mostram a função menu que foi feita pelo programador para permitir o usuário escolher qual máscara vai ser utilizada.

O trecho de código que vai das linhas 81 a 101 mostra através das linhas 81 a 90 a tentativa de abertura do vídeo e consequentemente a abertura de duas janelas mostrando a imagem original e a imagem com filtro aplicado pelas linhas 93 e 94. Nas linhas 96 a 99 temos o procedimento padrão para construção da matriz que será usada como máscara de filtragem. A variável mask recebe uma matriz de tamanho 3X3 em ponto flutuante (CV_32F) com valores iniciais iguais ao do array media que é repassado. O tipo da matriz precisa ser estabelecido em ponto flutuante, posto que as operações de cálculo contarão com a presença de números fracionários. 

O uso da função scaleAdd() serve para dar o ganho de 1/9 nos coeficientes do filtro da média. A operação multiplica o primeiro argumento pelo segundo, soma com o terceiro argumento (neste caso, uma matriz de zeros) e armazena o resultado no terceiro argumento, mask1. Logo em seguida, a troca entre as matrizes mask e mask1 ocorre para que use apenas a matriz mask no cálculo da convolução digital.

Por fim na linha 101 temos a chamada da função menu() para pedir ao usuário que escolha o tipo de máscara a ser utilizada.

Nas linhas 106 e 107 temos em um loop infinito que as imagens coloridas captadas pela camera do computador são enviadas a matriz cap e depois tem os seus pixels convertidos em tons de cinza pela função cvtColor. Nas linhas 110 e 111 temos um giro horizontal da imagem, para aparentar um espelho através da função flip(). Na linha 112 e 115 temos o cálculo da filtragem espacial. A imagem em tom de cinza na variável frame é convertida para outra equivalente com representação em ponto flutuante - frame32f. A conversão é necessária devido aos tipos de operação que serão realizados pela função filter2D().

A função filter2d() recebe então a matriz da imagem em ponto flutuante - frame32f - e produz a matriz frameFiltered, de acordo com o tipo do elemento da matriz de entrada - neste caso, CV_32F (ou float). O objeto Point(1,1) que é repassado como próximo argumento identifica a origem do sistema de coordenadas atribuído para a máscara que, neste caso, é o ponto central da matriz.   

Na linha 121 temos uma conversão da matriz frameFiltered para CV_8U que significa oito bits por pixel, ou seja, os pixels podem ir do valor 0 a 255 como normalmente é nas imagens e vídeos.

O restante do código apenas tem a função de apresentar um menu para o usuário escolher qual máscara aplicar e salvaar uma imagem do efeito do filtro laplaciano do gaussiano.

