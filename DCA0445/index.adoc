= DCA0445 - Processamento Digital de Imagens
Denis Medeiros <denis@dimap.ufrn.br> Pedro Henrique <pedrohenriquedemedeiros@gmail.com>
:toc:
:toc-placement: left
:toc-title: Sumário
:caution-caption: Cuidado 
:important-caption: Importante 
:note-caption: Nota 
:tip-caption: Dica 
:warning-caption: Atenção 
:appendix-caption: Apêndices 
:example-caption: Exemplo 
:figure-caption: Figura 
:table-caption: Tabela
:stem:
//:numbered:
:source-highlighter: pygments
:icons: font
:linkattrs:
:imagesdir: ./img
:iconsdir: ./icons
:stylesdir: ./css
:scriptsdir: ./js
:sourcedir: ./src

Esta página contém uma série de exercícios sobre processamento digital de imagens implementados em C++ com a biblioteca OpenCV. Todos eles, bem como os textos introdutórios são de crédito do professor Dr. link:http://agostinhobritojr.github.io/[Agostinho de Medeiros Brito Junior, window="_blank"], professor da Universidade Federal do Rio Grande do Norte e responsável pelo curso link:http://agostinhobritojr.github.io/tutoriais/pdi/[DCA0445 - Processamento Digital de Imagens, window="_blank"].

== Manipulando pixels em uma imagem

=== Seção 3.2 - Exercício 1
****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/pixels.cpp[exemplos/pixels.cpp, window="_blank"] como referência, implemente um  programa regions.cpp. Esse programa deverá solicitar ao usuário as coordenadas  de dois pontos stem:[P_1] e stem:[P_2]  localizados dentro dos limites do  tamanho da imagem e exibir que lhe for fornecida. Entretanto, a região definida  pelo retângulo de vértices opostos definidos pelos pontos stem:[P_1] e stem:[P_2] será exibida com o negativo da imagem na região correspondente. 

O efeito é ilustrado na figura regiões (abaixo).

[[img-regioes]] 
.Figura regioes.png
image::regioes.png[Regiões, 400, 400] 
****

Para resolver o exercício acima, o seguinte programa foi desenvolvido:

.regioes.cpp
[[regioes]]
[source,cpp,linenums]
----
include::{sourcedir}/regioes/regioes.cpp[]
----

A estratégia adotada neste programa consiste em receber do usuário dois pontos, criar um retângulo a partir deles e calcular o negativo deste retângulo. 

As primeiras linhas do programa (linha 21 à linha 36) consiste na validação dos dados fornecidos pelo usuário, ou seja, se o usuário inseriu o número correto as coordenadas x e y de dois pontos e depois se também inseriu uma imagem para retirar o negativo de uma região dela. Depois nas linhas 39 à 64 temos a verificação de que os dados referentes aos dois pontos necessários ao programa são de fato números, pelo uso da função stoi() e então verifica-se se os pontos pertencem a imagem utilizando os comandos imagem.rols e imagem.cols. 

Uma vez que os dois pontos são válidos, é criado um retângulo (linha 66) e, finalmente, é relizado uma iteração sob todos aqueles pixels representados pelo retângulo dentro da própria matriz __image__ (linha 67 à linha 73), de modo que é calculado o negativo de cada pixel subtraindo seu  valor de 255, em que os pixels são acessados pelo método at, recebendo o dado __unsigned char__ da imagem em tons de cinza. Por fim, a imagem processada é exibida na tela.


====
.Exemplo de execução
* Comando: ./regioes onca.png 20 20 200 200
* Foto de entrada: 

[[img-onca]] 
.Figura onca.png original
image::onca.png[Regiões, 400, 400] 

* Foto de saída: 

[[img-onca-regions]] 
.Figura onca.png após processamento
image::onca-regioes.png[Regiões, 400, 400] 

====

=== Seção 3.2 - Exercício 2
****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/pixels.cpp[exemplos/pixels.cpp, window="_blank"] como referência, implemente um programa trocaregioes.cpp. Seu programa deverá trocar os quadrantes em diagonal na imagem. Explore o uso da classe Mat e seus construtores para criar as regiões que serão trocadas. O efeito é ilustrado na Figura Troca de regiões (abaixo).

[[img-regioes]] 
.Figura trocaregioes.png
image::trocaregioes.png[Troca Regiões, 400, 400] 
****

A versão modificada do programa pixels.cpp pode ser vista abaixo:

.trocaregioes.cpp
[[trocaregioes]]
[source,cpp,linenums]
----
include::{sourcedir}/trocaregioes/trocaregioes.cpp[]
----

O objetivo do programa acima foi criar 4 sub-matrizes representando cada quadrante para que depois elas pudessem ser concantenadas em uma nova matriz, de modo a representar os quadrantes trocados.

A criação das submatrizes ocorrem utilizando o próprio construtor da classe *Mat* (da linha 39 à 42), que permite receber a matriz original e um retângulo representando a ser extraída para criação da nova submatriz. Os retângulos são montados tomando como referência o início, fim e pontos médios horizontais e verticais da matriz original.

Com as submatrizes criadas, primeiro são montadas as partes superior e inferior do resultado final (linhas 48 e 53), através da função hconcat(), que primeiro realiza o concatenamento horizontal da metade de baixo da figura original e depois o concatenamento da metade de cima da figura original, em que as submatrizes q1, q2, q3 e q4 são colocadas nas matrizes temp1 e temp2. Com esses dois resultados intermediários, por fim, é realizado um concatenamento vertical (linha 58), com a função vconcat(), que produz o resultado final.

====
.Exemplo de execução
* Comando: ./trocaregioes gato.png
* Foto de entrada: 

[[img-gato]] 
.Figura gato.png original
image::gato.png[Troca Regioes, 400, 400] 

* Foto de saída: 

[[img-gato-trocaregioes]] 
.Figura gato.png após processamento
image::gato-trocaregioes.png[Regiões, 400, 400] 

====

== Preenchendo regiões

=== Seção 4.2 - Exercício 1
****
Observando-se o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/labeling.cpp[labeling.cpp] como exemplo, é possível verificar que caso existam mais de 255 objetos na cena, o processo de rotulação poderá ficar comprometido. Identifique a situação em que isso ocorre e proponha uma solução para este problema.
****

O algoritmo padrão de labeling fornecido pelo professor contem um problema, pois utiliza a própria cor do pixel rotulado para armazenar a contagem de elementos. No caso de uma imagem em escala de cinza, em que cada pixel é representado por 1 byte, logo poder-se-ia contar apenas 255 elementos. Uma abordagem diferente seria utilizar a cor do pixel como um tipo de classificação para os objetos contados, de modo que os pixels de uma mesma categoria assumam apenas um rótulo específico, sendo reservado um contador à parte para contar quantos elementos dessa categoria foram encontrados.

=== Seção 4.2 - Exercício 2

****
Aprimore o algoritmo de contagem apresentado para identificar regiões com ou sem buracos internos que existam na cena. Assuma que objetos com mais de um buraco podem existir. Inclua suporte no seu algoritmo para não contar bolhas que tocam as bordas da imagem. Não se pode presumir, a priori, que elas tenham buracos ou não.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/labeling.cpp[labeling.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo: 

.rotulacao.cpp
[[rotulacao]]
[source,cpp,linenums]
----
include::{sourcedir}/rotulacao/rotulacao.cpp[]
----

A ideia por trás da contagem das bolhas baseiou-se no princípio de rotulação. Os rótulos foram definidos no início do programa, pois já sabia-se, a princípio, quais eram as cores de fundo e dos objetos da cena (linha 4 à linha 7).

Para realizar isso, foi necessário, inicialmente, remover todos os objetos presentes nas bordas da imagem, já que não é possível saber se eles continham ou não buracos iternos na região exterior à imagem (da linha 38 à linha 61). Para isso, foi utilizado um algoritmo de _flood fill_, mudando a cor do objeto encontrado para a mesma cor de fundo da cena.

Uma vez que as imagens localizadas na borda foram removidas, o passo seguinte foi mudar a cor de fundo da cena através do mesmo algoritmo de _flood fill_, iniciando do primeiro pixel da matriz da imagem (linha 64 à linha 66). Isso foi feito com o objetivo de fazer com que os elementos que continham buracos continuassem com tais buracos na cor de fundo antiga, já que, caso um objeto desses não fosse completamente fechado, o buraco seria preenchido pela nova cor de fundo.

Por fim, foi feita uma busca na imagem por qualquer região que ainda estivesse rotulado com a cor de fundo inicial (linha 69 à 81). Tal região seria, consequentemente, um buraco dentro de um objeto. Assim, o número de bolhas seria exatamente igual ao número de buracos encontrados. 


====
.Exemplo de execução
* Comando: ./rotulacao bolhas.png
* Foto de entrada: 

[[img-bolhas]] 
.Figura bolhas.png original
image::bolhas.png[Troca Regioes, 400, 400] 

* Foto de saída: 

[[img-gato-trocaregioes]] 
.Figura bolhas.png após processamento
image::bolhas-rotulacao.png[Regiões, 400, 400] 
====

== Manipulação de Histogramas

=== Seção 5.2 - Exercício 1

****
Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa equalize.cpp. Este deverá, para cada imagem capturada, realizar a equalização do histogram antes de exibir a imagem. Teste sua implementação apontando a câmera para ambientes com iluminações variadas e observando o efeito gerado. Assuma que as imagens processadas serão em tons de cinza.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/histogram.cpp[histogram.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo:

.equalizador.cpp
[[equalizador]]
[source,cpp,linenums]
----
include::{sourcedir}/equalizador/equalizador.cpp[]
----

A ideia por trás desse programa consiste em fazer a captura de uma imagem a partir da camera do programador e então fazer o processo de equalização da imagem, o qual consiste em uma distribuição mais uniforme dos valores da intensidade da distribuição, nesse caso o histograma.

Inicialmente o programa realiza a captura de um frame a partir da camera do computador do programador através da classe do opencv VideoCapture, evidenciado na linha 9. Nas linhas 32 e 33 define-se a largura e altura das imagens que serão usadas para desenhar os histogramas.  As imagens são criadas com o tipo CV_8UC1, ou seja, com 8 bits por pixel, com tipo de dados unsigned char contendo 1 canal de cor.

O processo de conversão da imagem colorida para a escala de cinza, através da função cvtColor(), evidenciado na linha 47. Depois temos o uso da função equalizeHist() para a equalização do histograma, evidenciado na linha 49. As outras linhas de código fazem o cálculo do histograma com a função calcHist(), sua normalização com a função normalize(), em relação ao número de linhas da imagem equalizada, a inserção dos histogramas nos frames através da funções line() e copyTo() e por fim uma mensagem para distinção das imagens mostradas nos frames com a função putText. 

====
.Exemplo de execução
* Comando: ./equalizador 
* Fotos de saída: 

[[img-ImagemOriginalEscalaCinza]] 
.Figura ImagemOriginalEscalaCinza.png 
image::ImagemOriginalEscalaCinza.png[ImagemOriginalEscalaCinza, 400, 400] 

[[img-ImagemEqualizada]] 
.Figura ImagemEqualizada.png 
image::ImagemEqualizada.png[ImagemEqualizada, 400, 400] 

====

=== Seção 5.2 - Exercício 2

****
Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa motiondetector.cpp. Este deverá continuamente calcular o histograma da imagem (apenas uma componente de cor é suficiente) e compará-lo com o último histograma calculado. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, ative um alarme. Utilize uma função de comparação que julgar conveniente.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/histogram.cpp[histogram.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo:

.detectormovimento.cpp
[[detectormovimento]]
[source,cpp,linenums]
----
include::{sourcedir}/detectormovimento/detectormovimento.cpp[]
----

A ideia básica do programa é fazer o uso de duas imagens, uma será a imagem atual que aparece na camera e a outra será uma imagem base tirada momentos antes da imagem atual e será então utilizada a técnica de comparação de histograma para verificar se ouve algum movimento entre as imagens comparadas.
 
Nas linhas 6 e 9 verifica-se a inserção de um novo tempo de captura para a nova imagem base que consiste em 50ms e por conseguinte o limiar da sensibilidade da detecção do movimento que é de 0.99.

Na linha 28 temos a definição das variáveis inicio e fim do tipo std::chrono::time_point, que significam que são apenas pontos no tempo. Na linha 29 temos a variável que simboliza a variação do tempo inicial e final para então termos outra captura de uma imagem base. As linhas 32 e 35 mostram a separação entre os planos das componentes de cores RGB e as varáveis que vão ser responsáveis por guardar os seus histogramas. As linhas 38 a 78 tem a mesma função dos códigos utilizados no exércio 1 desta seção, com a diferença no termo CV_8UC3 que tem três canais de cor.

Na linha 80 o comando chrono::steady_clock::now(); pega o tempo atual e guarda na variável inicio e no começo do while infinito a variável fim recebe o valor do tempo atual pelo comando chrono::steady_clock::now(); e nas linhas 89 a 93 temos uma comparação entre a varável fim e inicio com o intuito da verificação da se a diferença de tempo foi maior que 50ms para então fazer uma nova captura para a imagem base. 

As linhas 95  a 127 são semelhantes no quesito que os seus códigos estão cumprindo a mesma função do que os códigos do exercício 1 desta seção com a diferença que estamos trabalhando com três planos da imagem colorida que são o RGB. Nas linhas 128 a 151 temos o uso da função calcHist() da comparação dos histogramas pelo método da correlação e depois vamos ter o teste para verificar se o limiar do método da correlação foi violado e assim informar ao usuário que ouve movimento na comparação da imagem base com a imagem atual.


== Filtragem Espacial I

=== Seção 6.2 Exercício 1

****
Utilizando o programa exemplos/filtroespacial.cpp como referência, implemente um programa laplgauss.cpp. O programa deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Compare o resultado desse filtro com a simples aplicação do filtro laplaciano.
****

O programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/filtroespacial.cpp[filtroespacial.cpp], disponibilizado pelo professor, foi adaptado e o resultado final pode ser visto abaixo:

.laplgauss.cpp
[[laplgauss]]
[source,cpp,linenums]
----
include::{sourcedir}/laplgauss/laplgauss.cpp[]
----

A ideia básica do programa é verificar a utilização dos diversos filtros espaciais definidos pelo professor no  link para o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/filtroespacial.cpp[filtroespacial.cpp] e que foram modificados no programa laplgauss.cpp e então aplicamos um filtro do laplaciano do gaussiano.

====
.Exemplo de execução
* Comando: ./laplgauss 
* Fotos de saída: 

[[img-Imagem_Filtro_Vertical]] 
.Figura Imagem_Filtro_Vertical.png 
image::Imagem_Filtro_Vertical.png[Imagem_Filtro_Vertical, 400, 400] 

[[img-Imagem_Filtro_Horizontal]] 
.Figura Imagem_Filtro_Horizontal.png 
image::Imagem_Filtro_Horizontal.png[Imagem_Filtro_Horizontal, 400, 400] 

[[img-Imagem_Filtro_Mediana]] 
.Figura Imagem_Filtro_Mediana.png 
image::Imagem_Filtro_Mediana.png[Imagem_Filtro_Mediana, 400, 400] 

[[img-Imagem_Filtro_Gauss]] 
.Figura Imagem_Filtro_Gauss.png 
image::Imagem_Filtro_Gauss.png[Imagem_Filtro_Gauss, 400, 400] 

[[img-Imagem_Filtro_Laplaciano]] 
.Figura Imagem_Filtro_Laplaciano.png 
image::Imagem_Filtro_Laplaciano.png[Imagem_Filtro_Laplaciano, 400, 400]

[[img-Imagem_Filtro_LaplacianoGaussiano]] 
.Figura Imagem_Filtro_LaplacianoGaussiano.png 
image::Imagem_Filtro_LaplacianoGaussiano.png[Imagem_Filtro_LaplacianoGaussiano, 400, 400]
====

As linhas 7 a 44 mostram os diferentes tipos de máscaras utilizadas, as quais são:

* Media
* Gauss
* Horizontal
* Vertical
* Laplaciano
* Laplaciano do gaussiano

A máscara do laplaciano do gaussiano foi obtida através da operação de convolução entre as máscaras de gauss e laplaciana.

As linhas 59 a 69 mostram a função menu que foi feita pelo programador para permitir o usuário escolher qual máscara vai ser utilizada.

O trecho de código que vai das linhas 81 a 101 mostra através das linhas 81 a 90 a tentativa de abertura do vídeo e consequentemente a abertura de duas janelas mostrando a imagem original e a imagem com filtro aplicado pelas linhas 93 e 94. Nas linhas 96 a 99 temos o procedimento padrão para construção da matriz que será usada como máscara de filtragem. A variável mask recebe uma matriz de tamanho 3X3 em ponto flutuante (CV_32F) com valores iniciais iguais ao do array media que é repassado. O tipo da matriz precisa ser estabelecido em ponto flutuante, posto que as operações de cálculo contarão com a presença de números fracionários. 

O uso da função scaleAdd() serve para dar o ganho de 1/9 nos coeficientes do filtro da média. A operação multiplica o primeiro argumento pelo segundo, soma com o terceiro argumento (neste caso, uma matriz de zeros) e armazena o resultado no terceiro argumento, mask1. Logo em seguida, a troca entre as matrizes mask e mask1 ocorre para que use apenas a matriz mask no cálculo da convolução digital.

Por fim na linha 101 temos a chamada da função menu() para pedir ao usuário que escolha o tipo de máscara a ser utilizada.

Nas linhas 106 e 107 temos em um loop infinito que as imagens coloridas captadas pela camera do computador são enviadas a matriz cap e depois tem os seus pixels convertidos em tons de cinza pela função cvtColor. Nas linhas 110 e 111 temos um giro horizontal da imagem, para aparentar um espelho através da função flip(). Na linha 112 e 115 temos o cálculo da filtragem espacial. A imagem em tom de cinza na variável frame é convertida para outra equivalente com representação em ponto flutuante - frame32f. A conversão é necessária devido aos tipos de operação que serão realizados pela função filter2D().

A função filter2d() recebe então a matriz da imagem em ponto flutuante - frame32f - e produz a matriz frameFiltered, de acordo com o tipo do elemento da matriz de entrada - neste caso, CV_32F (ou float). O objeto Point(1,1) que é repassado como próximo argumento identifica a origem do sistema de coordenadas atribuído para a máscara que, neste caso, é o ponto central da matriz.   

Na linha 121 temos uma conversão da matriz frameFiltered para CV_8U que significa oito bits por pixel, ou seja, os pixels podem ir do valor 0 a 255 como normalmente é nas imagens e vídeos.

O restante do código apenas tem a função de apresentar um menu para o usuário escolher qual máscara aplicar e salvaar uma imagem do efeito do filtro laplaciano do gaussiano.


== Filtragem Espacial II

=== Seção 7.1 - Exercício 1

****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/addweighted.cpp[exemplos/addweighted.cpp, window="_blank"] como referência, implemente um programa tiltshift.cpp. Três ajustes deverão ser providos na tela da interface:

* um ajuste para regular a altura da região central que entrará em foco;

* um ajuste para regular a força de decaimento da região borrada;

* um ajuste para regular a posição vertical do centro da região que entrará em foco. Finalizado o programa, a imagem produzida deverá ser salva em arquivo.
****

A partir do programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/addweighted.cpp[exemplos/addweighted.cpp, window="_blank"], disponibilizado pelo professor, e com base na teoria apresentada no capítulo em questão, o seguinte programa que aplica o efeito de __tilt shift__ foi desenvolvido:

.tiltshift.cpp
[[tiltshift]]
[source,cpp,linenums]
----
include::{sourcedir}/tiltshift/tiltshift.cpp[]
----

A ideia do efeito de __tilt shift__, conforme descrito no link:http://agostinhobritojr.github.io/tutoriais/pdi/#_filtragem_no_domínio_espacial_ii[Capítulo 7, window="_blank"], consiste em "combinar a imagem original com sua versão filtrada com filtro passa-baixas, de sorte a produzir nas proximidades da borda o efeito do borramento enquanto se mantém na região central a imagem sem borramento".

Para tornar isso possível, o primeiro objetivo do programa é, então, receber uma imagem do usuário e imediatamente gerar sua versão filtrada, isto é, com efeito de borramento para que elas duas possam ser combinadas depois. Isso é feito na linha 127, através da função *borrarImagem()*. Esta função, basicamente, aplica o fitro da média de tamanho stem:[3 times 3]  seis vezes seguidas na imagem original, para provocar um borramento bem intenso. 

Com a imagem original e a imagem borrada produzidas, o passo seguinte é aplicar a função stem:[g(x,y) = α(x)f(x,y) + (1−α(x))bf(x,y)], sendo stem:[g(x,y)] a imagem com efeito de tilt-shit aplicado, stem:[f(x,y)] a imagem original e stem:[bf(x,y)] a imagem original após o efeito de borramento. A forma sobre como ambas as imagens de entrada (a original e a versão borrada) serão combinadas depende da função stem:[α(x)], definida por stem:[α(x) = \frac{1}{2} (\frac{tanh(x)−l1}{d}−\frac{tanh(x)−l2}{d})], "onde stem:[l1] e stem:[l2] são as linhas cujo valor de stem:[α]  assume valor em torno de 0.5, caso os dois valores possuam uma distância adequada um do outro, e stem:[d]  indica a força do decaimento da região totalmente oriunda da imagem original para a região totalmente oriunda da imagem borrada".

No programa acima, o cálculo do stem:[α(x)] é feito na através da função *calcularImagemFinal()*, definida na linha 52. Ela usará os parâmetros da função escolhidos pelo usuário através da mudança das barras de rolagem, calculará se valor e gerará a imagem final resultante stem:[g(x,y)]. Essa imagem gerada é sempre atualizada na janela do programa e, quando o usuário concluir sua configuração, ele pode pressionar qualquer teclada para encerrar o programa e salvar o resultado. 

Por fim, vale ressaltar que, antes da imagem original ser processa, ocorre um aumento na sua saturação com o intuito de deixar as cores mais vivas. Isso é importante para tornar o efeito de _tilt-shift_ mais forte.

====

Exemplo da janela de configuração dos parâmetros

[[img-janela-tiltshift]] 
.Figura janela-tiltshift.png
image::janela-tiltshift.png[Janela Tilt-shift] 


.Exemplo de execução 1
* Comando: ./tiltshift saopaulo.png
* Foto de entrada: 

[[img-saopaulo]] 
.Figura saopaulo.png original
image::saopaulo.png[São Paulo] 

* Foto de saída: 

[[img-saopaulo-tiltshift]] 
.Figura saopaulo.png após processamento
image::saopaulo-tiltshift.png[São Paulo - Tilt Shift] 

.Exemplo de execução 2
* Comando: ./tiltshift china.png
* Foto de entrada: 

[[img-china]] 
.Figura china.png original
image::china.png[China] 

* Foto de saída: 

[[img-china-tiltshift]] 
.Figura china.png após processamento
image::china-tiltshift.png[China - Tilt Shift] 
====

=== Seção 7.1 - Exercício 2

****
Utilizando o programa link:http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/addweighted.cpp[exemplos/addweighted.cpp, window="_blank"] como referência, implemente um programa tiltshiftvideo.cpp. Tal programa deverá ser capaz de processar um arquivo de vídeo, produzir o efeito de tilt-shift nos quadros presentes e escrever o resultado em outro arquivo de vídeo. A ideia é criar um efeito de miniaturização de cenas. Descarte quadros em uma taxa que julgar conveniente para evidenciar o efeito de stop motion, comum em vídeos desse tipo.
****

A solução deste exercício é apenas uma adaptação do programa anterior (<<tiltshift>>), conforme pode ser visto a seguir:

.tiltshiftvideo.cpp
[[tiltshiftvideo]]
[source,cpp,linenums]
----
include::{sourcedir}/tiltshiftvideo/tiltshiftvideo.cpp[]
----

A ideia deste programa foi abrir um arquivo de vídeo e sair aplicando o efeito de _tilt-shift_ do exemplo anterior a cada quadro do vídeo. Para isso, é apresentado usuário uma janela com o primeiro quadro do vídeo para ele definir como o filtro será aplicado (linha 164 à linha 179). Uma vez que isso é concluído, o usuário pressionar qualquer tecla para iniciar o processamento (linha 189 +a linha 222).

Durante o processamento, foi adicionado um pequeno trecho para descartar alguns quadros do vídeo para produzir um efeito de _stop-motion_ (linha 194 à linha 199). Além disso, é exibido para o usuário o progresso atual do processamento em percentagem (linha 218), já que, dependendo do vídeo, isso pode demorar e é importante que o usuário consiga estimar o tempo total.

====

Exemplo da janela de configuração dos parâmetros que aparece no primeiro quadro do vídeo.

[[img-janela-tiltshiftvideo]] 
.Figura janela-tiltshiftvideo.png
image::janela-tiltshiftvideo.png[Janela Tilt-shift Vídeo] 


.Exemplo de execução
* Comando: ./tiltshiftvideo congestionamento.mp4
* Vídeo de entrada: 

[[video-congestionamento]] 
.Vídeo congestionamento.mp4 original
video::5tiWGREedi4[youtube, width=640, height=480, options="loop"]

* Vídeo de saída: 

[[video-congestionamento-tiltshift]] 
.Vídeo congestionamento.mp4 processado
video::1ziU0PYewVU[youtube, width=640, height=480, options="loop"]

====
>>>>>>> 23b77eb497a46354eb352ba8013c93b19fa4be2a
